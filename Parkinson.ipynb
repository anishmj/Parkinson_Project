{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPLcyNeNO7fyz36iDrB/yVj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anishmj/Parkinson_Project/blob/main/Parkinson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwXCkYBBGQ-5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# loading the data from csv file to a Pandas DataFrame\n",
        "parkinsons_data = pd.read_csv('/content/parkinsons.csv')\n",
        "\n",
        "# separating the features and target\n",
        "X = parkinsons_data.drop(columns=['name', 'status'], axis=1)\n",
        "Y = parkinsons_data['status']\n",
        "\n",
        "# splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "# feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# applying PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # You can adjust the number of components\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# define the models\n",
        "svm_model = svm.SVC(kernel='linear', probability=True)  # SVM with probability estimates\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=2)  # Random Forest model\n",
        "\n",
        "# hybrid model using voting classifier\n",
        "hybrid_model = VotingClassifier(estimators=[\n",
        "    ('svm', svm_model),\n",
        "    ('rf', rf_model)\n",
        "], voting='soft')  # 'soft' voting averages probabilities\n",
        "\n",
        "# training the hybrid model on the training data\n",
        "hybrid_model.fit(X_train_pca, Y_train)\n",
        "\n",
        "# accuracy score on training data\n",
        "X_train_prediction = hybrid_model.predict(X_train_pca)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print('Accuracy score on training data: ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on test data\n",
        "X_test_prediction = hybrid_model.predict(X_test_pca)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print('Accuracy score on test data: ', test_data_accuracy)\n",
        "\n",
        "# prediction on new data\n",
        "input_data = (197.07600,206.89600,192.05500,0.00289,0.00001,0.00166,0.00168,0.00498,0.01098,0.09700,0.00563,0.00680,0.00802,0.01689,0.00339,26.77500,0.422229,0.741367,-7.348300,0.177551,1.743867,0.085569)\n",
        "\n",
        "# changing input data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "\n",
        "# applying PCA to input data\n",
        "input_data_pca = pca.transform(std_data)\n",
        "\n",
        "# prediction using the hybrid model\n",
        "prediction = hybrid_model.predict(input_data_pca)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "    print(\"The Person does not have Parkinson's Disease\")\n",
        "else:\n",
        "    print(\"The Person has Parkinson's Disease\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Git with your GitHub email and name\n",
        "!git config --global user.email \"mjanish19@gmail.com\"\n",
        "!git config --global user.name \"Anish MJ\"\n"
      ],
      "metadata": {
        "id": "acefNzo4ABCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git"
      ],
      "metadata": {
        "id": "klzdLZYQANUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct GitHub repository URL\n",
        "!git clone https://github.com/anishmj/Parkinson_Project.git\n"
      ],
      "metadata": {
        "id": "eKpDfzG3AU9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Parkinson_Project"
      ],
      "metadata": {
        "id": "YILh5k3-BWRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move your code file into the repo\n",
        "!mv /content/your_parkinson_code.py /content/Parkinson_Project/\n"
      ],
      "metadata": {
        "id": "HUcfZbEJBdfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to your repo folder\n",
        "%cd https://github.com/anishmj/Parkinson_Project.git\n",
        "\n",
        "# Add the files to staging\n",
        "!git add .\n",
        "\n",
        "# Commit the changes\n",
        "!git commit -m \"Added Parkinson code\"\n",
        "\n",
        "# Push the changes to GitHub\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "id": "HNM5bDbFAn2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# loading the data from csv file to a Pandas DataFrame\n",
        "parkinsons_data = pd.read_csv('/content/parkinsons.csv')\n",
        "\n",
        "# separating the features and target\n",
        "X = parkinsons_data.drop(columns=['name', 'status'], axis=1)\n",
        "Y = parkinsons_data['status']\n",
        "\n",
        "# splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "# feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# applying PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # You can adjust the number of components\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# define the models\n",
        "svm_model = svm.SVC(kernel='linear', probability=True)  # SVM with probability estimates\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=2)  # Random Forest model\n",
        "\n",
        "# hybrid model using voting classifier\n",
        "hybrid_model = VotingClassifier(estimators=[\n",
        "    ('svm', svm_model),\n",
        "    ('rf', rf_model)\n",
        "], voting='soft')  # 'soft' voting averages probabilities\n",
        "\n",
        "# training the hybrid model on the training data\n",
        "hybrid_model.fit(X_train_pca, Y_train)\n",
        "\n",
        "# accuracy score on training data\n",
        "X_train_prediction = hybrid_model.predict(X_train_pca)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print('Accuracy score on training data: ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on test data\n",
        "X_test_prediction = hybrid_model.predict(X_test_pca)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print('Accuracy score on test data: ', test_data_accuracy)\n",
        "\n",
        "# prediction on new data\n",
        "input_data = (0, 0, 0, 0, 0,0, 0, 0,\n",
        "              0, 0, 0, 0, 0, 0, 0, 0,\n",
        "              0, 0, 0, 0, 0, 0)\n",
        "\n",
        "# changing input data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "\n",
        "# applying PCA to input data\n",
        "input_data_pca = pca.transform(std_data)\n",
        "\n",
        "# prediction using the hybrid model\n",
        "prediction = hybrid_model.predict(input_data_pca)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "    print(\"The Person does not have Parkinson's Disease\")\n",
        "else:\n",
        "    print(\"The Person has Parkinson's Disease\")\n"
      ],
      "metadata": {
        "id": "uDQFUn40GgVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# loading the data from csv file to a Pandas DataFrame\n",
        "parkinsons_data = pd.read_csv('/content/parkinsons.csv')\n",
        "\n",
        "# separating the features and target\n",
        "X = parkinsons_data.drop(columns=['name', 'status'], axis=1)\n",
        "Y = parkinsons_data['status']\n",
        "\n",
        "# splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "# feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# applying PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # You can adjust the number of components\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# define the models\n",
        "svm_model = svm.SVC(kernel='linear', probability=True)  # SVM with probability estimates\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=2)  # Random Forest model\n",
        "\n",
        "# hybrid model using voting classifier\n",
        "hybrid_model = VotingClassifier(estimators=[\n",
        "    ('svm', svm_model),\n",
        "    ('rf', rf_model)\n",
        "], voting='soft')  # 'soft' voting averages probabilities\n",
        "\n",
        "# training the hybrid model on the training data\n",
        "hybrid_model.fit(X_train_pca, Y_train)\n",
        "\n",
        "# accuracy score on training data\n",
        "X_train_prediction = hybrid_model.predict(X_train_pca)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print('Accuracy score on training data: ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on test data\n",
        "X_test_prediction = hybrid_model.predict(X_test_pca)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print('Accuracy score on test data: ', test_data_accuracy)\n",
        "\n",
        "# prediction on new data\n",
        "input_data = (152.31, 210.76, 90.24, 0.00891, 0.000058, 0.00412, 0.00455, 0.01237,\n",
        "              0.03824, 0.320, 0.1745, 0.02312, 0.02987, 0.05234, 0.03567, 18.45,\n",
        "              0.497, 0.753, -7.115, 0.269, 2.452, 0.189)\n",
        "\n",
        "# changing input data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "\n",
        "# applying PCA to input data\n",
        "input_data_pca = pca.transform(std_data)\n",
        "\n",
        "# prediction using the hybrid model\n",
        "prediction = hybrid_model.predict(input_data_pca)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "    print(\"The Person does not have Parkinson's Disease\")\n",
        "else:\n",
        "    print(\"The Person has Parkinson's Disease\")\n"
      ],
      "metadata": {
        "id": "9BHngCgYHLEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# loading the data from csv file to a Pandas DataFrame\n",
        "parkinsons_data = pd.read_csv('/content/parkinsons.csv')\n",
        "\n",
        "# separating the features and target\n",
        "X = parkinsons_data.drop(columns=['name', 'status'], axis=1)\n",
        "Y = parkinsons_data['status']\n",
        "\n",
        "# splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "# feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# applying PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # You can adjust the number of components\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# define the models\n",
        "svm_model = svm.SVC(kernel='linear', probability=True)  # SVM with probability estimates\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=2)  # Random Forest model\n",
        "\n",
        "# hybrid model using voting classifier\n",
        "hybrid_model = VotingClassifier(estimators=[\n",
        "    ('svm', svm_model),\n",
        "    ('rf', rf_model)\n",
        "], voting='soft')  # 'soft' voting averages probabilities\n",
        "\n",
        "# training the hybrid model on the training data\n",
        "hybrid_model.fit(X_train_pca, Y_train)\n",
        "\n",
        "# accuracy score on training data\n",
        "X_train_prediction = hybrid_model.predict(X_train_pca)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print('Accuracy score on training data: ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on test data\n",
        "X_test_prediction = hybrid_model.predict(X_test_pca)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print('Accuracy score on test data: ', test_data_accuracy)\n",
        "\n",
        "# prediction on new data\n",
        "input_data = (145.78,198.56,82.12,0.00945,0.000065,0.00458,0.00491,0.01374,\n",
        "              0.04123,0.355,0.01897,0.02467,0.03123,0.05691,0.03845,17.89,\n",
        "              0.521,.781,-7.452,.275,2.563,.201)\n",
        "\n",
        "# changing input data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "\n",
        "# applying PCA to input data\n",
        "input_data_pca = pca.transform(std_data)\n",
        "\n",
        "# prediction using the hybrid model\n",
        "prediction = hybrid_model.predict(input_data_pca)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "    print(\"The Person does not have Parkinson's Disease\")\n",
        "else:\n",
        "    print(\"The Person has Parkinson's Disease\")\n"
      ],
      "metadata": {
        "id": "GYyItjivHt1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# loading the data from csv file to a Pandas DataFrame\n",
        "parkinsons_data = pd.read_csv('/content/parkinsons.csv')\n",
        "\n",
        "# separating the features and target\n",
        "X = parkinsons_data.drop(columns=['name', 'status'], axis=1)\n",
        "Y = parkinsons_data['status']\n",
        "\n",
        "# splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "# feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# applying PCA for dimensionality reduction\n",
        "pca = PCA(n_components=10)  # You can adjust the number of components\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# define the models\n",
        "svm_model = svm.SVC(kernel='linear', probability=True)  # SVM with probability estimates\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=2)  # Random Forest model\n",
        "\n",
        "# hybrid model using voting classifier\n",
        "hybrid_model = VotingClassifier(estimators=[\n",
        "    ('svm', svm_model),\n",
        "    ('rf', rf_model)\n",
        "], voting='soft')  # 'soft' voting averages probabilities\n",
        "\n",
        "# training the hybrid model on the training data\n",
        "hybrid_model.fit(X_train_pca, Y_train)\n",
        "\n",
        "# accuracy score on training data\n",
        "X_train_prediction = hybrid_model.predict(X_train_pca)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print('Accuracy score on training data: ', training_data_accuracy)\n",
        "\n",
        "# accuracy score on test data\n",
        "X_test_prediction = hybrid_model.predict(X_test_pca)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print('Accuracy score on test data: ', test_data_accuracy)\n",
        "\n",
        "# prediction on new data\n",
        "input_data = (210.23,239.67,190.45,0.00110,0.000007,0.00078,0.00090,0.00234,\n",
        "              0.01476,0.125,0.00678,0.00845,0.01123,0.02034,0.0123,25.34,\n",
        "              0.312,0.689,-4.120,0.175,2.067,0.078)\n",
        "\n",
        "# changing input data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "\n",
        "# applying PCA to input data\n",
        "input_data_pca = pca.transform(std_data)\n",
        "\n",
        "# prediction using the hybrid model\n",
        "prediction = hybrid_model.predict(input_data_pca)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "    print(\"The Person does not have Parkinson's Disease\")\n",
        "else:\n",
        "    print(\"The Person has Parkinson's Disease\")\n"
      ],
      "metadata": {
        "id": "U74Dx0IbH2Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "PtW0g6bPJTKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the hybrid model\n",
        "hybrid_model.fit(X_train, Y_train)\n",
        "\n",
        "# Save the trained model to a .sav file\n",
        "model_filename = 'parkinsons_hybrid_model.sav'\n",
        "pickle.dump(hybrid_model, open(model_filename, 'wb'))\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "id": "rMlEmodNJV5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('scaler.sav', 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)"
      ],
      "metadata": {
        "id": "Tm9py0igJWTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}